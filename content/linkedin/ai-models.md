---
title: How AI Models Respond to Simple Math Question
description: Understanding how current AI models answer simple maths question
tags:
  - Linkedin
  - AI
  - Technology
date: 2024-05-13
draft: false
---
  
We all learned about negative numbers in school. To see how current popular AI language models answer simple maths questions, I asked them: "What is 3-4?"
 

The results were quite interesting:

- [OpenAI](https://www.linkedin.com/feed/#)'s [ChatGPT](https://www.linkedin.com/feed/#) 3.5, [Meta](https://www.linkedin.com/feed/#)'s LLaMA3, [Alphabet Inc.](https://www.linkedin.com/feed/#)'s Gemini and [Perplexity](https://www.linkedin.com/feed/#) got it right without much fuss


But things got interesting with the other 2 models I tested
- [Ola](https://www.linkedin.com/feed/#)'s Krutim went on a tangent, giving multiple interpretations rather than solving the question
- [Mistral AI](https://www.linkedin.com/feed/#)-7B, which not only claimed my question was wrong but also modified my question to 4-3 before answering it

![AI Answering Maths Question](https://i.imgur.com/wzRzRmw.png)
So not all AI models are created equal as 2 of them struggled with simple maths Or maybe they felt it was beneath them to answer such a simple question
